---
title: "Second Predictive Analysis"
author: "Michael Harrison"
date: "10/10/2017"
output: rmarkdown::github_document
---

# Document Description
This markdown document contains the second predictive analysis of the data prepared by the functions in this folder. The last study utilized a limited set of data due to 

The aim is to predict the total stops of a production run given the breakdown of materials. 

# Data Preparation
## Load Packages and Functions
```{r}
# Load necessary package; source function to return table for analysis
library(caret)
source("productionBreakdown.R")
```
## Prepare Data
```{r}
# Data contains NAs generated from merging tables; removes NA rows
data <- na.omit(productionBreakdown())
# Removing row identifier (millstyle), and date
data <- subset(data, select = -c(millstyle, date))
```
## Partition Data for Training, Validation, & Testing
```{r}
#Establishes constant seed for consequent use in model development
seed <- 7

# Partition data to create training, validation, and testing sets;
# First split: 60/40 training/validation_testing
set.seed(seed)
inVal <- createDataPartition(data$totalstops,
                             p = .6,
                             list = FALSE)
val_test <- data[-inVal,]
training <- data[inVal,]

# Second split: 50/50 validation/testing
set.seed(seed)
inTrain <- createDataPartition(val_test$totalstops, 
                               p = .5,
                               list = FALSE)
validation <- val_test[inTrain,]
testing <- val_test[-inTrain,]
```

### Data set dimensions
```{r}
dataset.dimensions <- list(Training = dim(training), 
                          Validation = dim(validation), 
                          Testing = dim(testing))
dataset.dimensions
```


# Baseline Model Fit
## Baseline Models Training
```{r}
# Set training control parameters for repeated cross validation and evaluation metric
trainControl <- trainControl(method = "repeatedCV",
                             number = 10,
                             repeats = 3,
                             allowParallel = TRUE)
metric <- "RMSE"

# Loads Parallel processing libraries
library(parallel)
library(doParallel)

# Initializes Parallel Processing
cluster <- makeCluster(detectCores()-1)
registerDoParallel(cluster)

# SVM
set.seed(seed)
fit.svm <- train(totalstops~.,
                 data = training,
                 method = "svmRadial",
                 metric = metric,
                 preProc=c("center", "scale"),
                 trControl = trainControl)

# XGBLinear
set.seed(seed)
fit.xgbLinear <- train(totalstops~.,
                 data = training,
                 method = "xgbLinear",
                 metric = metric,
                 preProc=c("center", "scale"),
                 trControl = trainControl)

# Random Forest
set.seed(seed)
fit.rf <- train(totalstops~.,
                data = training,
                method = "rf",
                metric = metric,
                preProc=c("center", "scale"),
                trControl = trainControl)

# Stops Parallel Processing
stopCluster(cluster)
registerDoSEQ()

# Results
fit.results <- resamples(list(SVM=fit.svm,
                              RF=fit.rf,
                              XGBLin = fit.xgbLinear))
```

## Baseline Model Results
```{r}
dotplot(fit.results)
```

```{r}
summary(fit.results)
```

# Baseline Model Validation
## Data PreProcessing and Training Parameters
```{r}
# preprocesses data for use in prediction
X <- validation[,1:16]
Y <- validation[,17]

# Standardize Data
preProcessParams <- preProcess(X, method = c("center", "scale"))

# Transforms the validation test set to preprocessing parameters
transf.validation <- predict(preProcessParams, X)

# Validation training control parameters; creates one model based on hyperparameters passed
validationControl <- trainControl(method = "none",
                                  number = 0)
metric = "RMSE"
```

## SVM Validation
### SVM tuning parameters
```{r}
tunedSigma <- fit.svm$bestTune$sigma
tunedC <- fit.svm$bestTune$C
```

### SVM Validation Model Training and Prediction
Train model with tuned hyperparameters and predict on validation set
```{r}
# SVM Final Model
tuneGrid <- expand.grid(.sigma = tunedSigma,
                        .C = tunedC)

set.seed(seed)
svmModel <- train(totalstops~.,
                  data = training,
                  method = "svmRadial",
                  metric = metric,
                  preProcess= c("center", "scale"),
                  tuneGrid = tuneGrid,
                  trControl = validationControl)

#SVM Validation
set.seed(seed)
svmPredictions <- predict(svmModel, transf.validation)
svmRMSE <- RMSE(svmPredictions, validation$totalstops)
```

### SVM Validation Results
```{r}
svm.results <- list(baselineRMSE = min(fit.svm$results$RMSE),
                    validationRMSE = svmRMSE,
                    difference = min(fit.svm$results$RMSE) - svmRMSE)
svm.results
```


## XGBLinear Validation
### XGBLinear tuning Parameters
```{r}
# Set XGBlinear tuning parameters to global variable
xgbNrounds <- fit.xgbLinear$finalModel$tuneValue$nrounds
xgbLambda <- fit.xgbLinear$finalModel$tuneValue$lambda
xgbAlpha <- fit.xgbLinear$finalModel$tuneValue$alpha
xgbEta <- fit.xgbLinear$finalModel$tuneValue$eta
```

### XGBLinear Validation Model Training and Prediction
```{r}
tuneGrid <- expand.grid(.nrounds = xgbNrounds,
                        .lambda = xgbLambda,
                        .alpha = xgbAlpha,
                        .eta = xgbEta)

set.seed(seed)
xgbLinModel <- train(totalstops~.,
                  data = training,
                  method = "xgbLinear",
                  metric = metric,
                  preProcess= c("center", "scale"),
                  tuneGrid = tuneGrid,
                  trControl = validationControl)

# XGBLinear Validation
set.seed(seed)
xgbLinPredictions <- predict(xgbLinModel, transf.validation)
xgbLinRMSE <- RMSE(xgbLinPredictions, validation$totalstops)
```

### XGBLinear Validation Results
```{r}
xgbLinear.results <- list(baselineRMSE = min(fit.xgbLinear$results$RMSE),
                          validationRMSE = xgbLinRMSE,
                          difference = min(fit.xgbLinear$results$RMSE) - xgbLinRMSE)
xgbLinear.results
```


## RandomForest Validation Validation Model Training and Prediction
### RandomForest tuning Parameters
```{r}
# Set RandomForest tuning parameter to global variable
rfMtry <- fit.rf$bestTune$mtry
```

### RandomForest Validation Model Training and Prediction
```{r}
tuneGrid <- expand.grid(.mtrt = rfMtry)

set.seed(seed)
rfModel <- train(totalstops~.,
                 data = training,
                 method = "rf",
                 metric = metric,
                 preProcess= c("center", "scale"),
                 tuneGrid = tuneGrid,
                 trControl = validationControl)

# RandomForest Validation
set.seed(seed)
rfPredictions <- predict(rfModel, transf.validation)
rfRMSE <- RMSE(rfPredictions, validation$totalstops)
```

### RandomForest Validation Results
```{r}
rf.results <- list(baselineRMSE = min(fit.rf$results$RMSE),
                   validationRMSE = rfRMSE,
                   difference = min(fit.rf$results$RMSE) - rfRMSE)
rf.results
```



## Validation Comparison
```{r}
validationResults <- rbind(SVM = svm.results, 
                           XGBLinear = xgbLinear.results, 
                           RandomForest = rf.results)
        
validationResults
```

# Model Tuning
## SVM Tuning

## XGBLinear Tuning

## RandomForest Tuning 

### Tuning mtry  
```{r}
# Load packages
library(parallel);library(doParallel)

#Grid Search Tuning
trainControl <- trainControl(method = "repeatedcv", 
                             number = 10, 
                             repeats = 3, 
                             search = "grid",
                             allowParallel = TRUE)
metric = "RMSE"
tuenGrid <- expand.grid(.mtry = c(5:15))

#Initializes Parallel Processing
cluster <- makeCluster(detectCores()-1)
registerDoParallel(cluster)

#Fits model with mtry value 
set.seed(seed)
fit.rfGrid <- train(totalstops~.,
                 data = training,
                 method = "rf",
                 metric = metric,
                 preProcess = c("center", "scale"),
                 tuneGrid = tuneGrid,
                 trControl = trainControl)

#Stops Parallel Processing
stopCluster(cluster)
registerDoSEQ()
```

### mtry Tuning Results
```{r}
plot(fit.rfGrid)
```

### Using optimal mtry value, search for optimal tree value
```{r}
rfMtry <- fit.rfGrid$bestTune$mtry

trainControl <- trainControl(method="repeatedcv", 
                             number=10, 
                             repeats=3, 
                             allowParallel = TRUE)
tuneGrid <- expand.grid(.mtry= rfMtry)
metric <- "RMSE"

#Initializes Parallel Processing
cluster <- makeCluster(detectCores()-1)
registerDoParallel(cluster)

modellist <- list()
for (ntree in c(1700, 1900, 2100, 2200, 2300, 2500)) {
  set.seed(seed)
  fit <- train(totalstops~., 
               data=training, 
               method="rf", 
               metric=metric, 
               tuneGrid=tuneGrid,
               trControl=trainControl, 
               ntree=ntree)
  key <- toString(ntree)
  modellist[[key]] <- fit
}

#Stops Parallel Processing
stopCluster(cluster)
registerDoSEQ()
```


```{r}
# Set to global variable
ntree.results <- resamples(modellist)
summary(ntree.results)
```


### ntree Tuning Results

```{r}
dotplot(ntree.results)
```

### Set ntree to global variable
```{r}
rfNtree <- 2300
```


### Tuned mtry and ntree in Random Forest

```{r}
validationControl <- trainControl(method = "none",
                                  number = 0)
tuneGrid <- expand.grid(.mtry = rfMtry)
metric = "RMSE"

#Initialize Parallel Processing
cluster <- makeCluster(detectCores()-1)
registerDoParallel(cluster)

#Train model with tuned parameters
set.seed(seed)
rfModelTuned <- train(totalstops~.,
                  data = training,
                  method = "rf",
                  metric = metric,
                  preProcess= c("center", "scale"),
                  tuneGrid = tuneGrid,
                  ntree = rfNtree,
                  trControl = validationControl)

#Stops Parallel Processing
stopCluster(cluster)
registerDoSEQ()

# Predict on Validation set
set.seed(seed)
rfTunedPredictions <- predict(rfModelTuned, transf.validation)
rfTunedRMSE <- RMSE(rfTunedPredictions, validation$totalstops)
rfTunedRMSE
```

